{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Function to read YOLO label files\n",
    "def read_yolo_label(label_path):\n",
    "    boxes = []\n",
    "    try:\n",
    "        with open(label_path, 'r') as file:\n",
    "            for line in file.readlines():\n",
    "                values = line.strip().split()\n",
    "                class_id = int(values[0])  # Class ID\n",
    "                x_center, y_center, width, height = map(float, values[1:])  # YOLO format\n",
    "                boxes.append([class_id, x_center, y_center, width, height])\n",
    "    except FileNotFoundError:\n",
    "        # Handle missing label files gracefully\n",
    "        print(f\"Label file not found: {label_path}. Returning empty boxes.\")\n",
    "    return torch.tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),  # Resize all images to the same size\n",
    "    transforms.ToTensor(),  # Convert to PyTorch tensors\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize RGB channels\n",
    "])\n",
    "\n",
    "class DriveYoloDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.label_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Populate image and label paths\n",
    "        for class_name in os.listdir(root_dir):  # Iterate through \"open\", \"closed\"\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                label = 0 if class_name.lower() == \"open\" else 1  # Assign numeric labels\n",
    "                for file_name in os.listdir(class_dir):\n",
    "                    if file_name.endswith(\".jpg\"):  # Look for image files\n",
    "                        label_path = os.path.splitext(os.path.join(class_dir, file_name))[0] + \".txt\"\n",
    "                        if os.path.exists(label_path):  # Check if label file exists\n",
    "                            self.image_paths.append(os.path.join(class_dir, file_name))\n",
    "                            self.label_paths.append(label_path)\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transforms to the image\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Load bounding box labels\n",
    "        label_path = self.label_paths[idx]\n",
    "        boxes = read_yolo_label(label_path)\n",
    "\n",
    "        # Fetch the open/closed label\n",
    "        eye_state_label = self.labels[idx]\n",
    "\n",
    "        return img, boxes, eye_state_label\n",
    "\n",
    "batch_size = 1\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle batches with varying numbers of bounding boxes.\n",
    "    \"\"\"\n",
    "    images, boxes, labels = zip(*batch)\n",
    "    images = torch.stack(images)  # Stack images into a single tensor\n",
    "    return images, boxes, torch.tensor(labels)\n",
    "\n",
    "drive_train_dir = './drive_image_data/train'\n",
    "train_dataset = DriveYoloDataset(root_dir=drive_train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set device to MPS if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "class yoloV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3)\n",
    "        self.maxPool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxPool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(192, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxPool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv9 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv10 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv14 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv15 = nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.conv16 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.maxPool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv17 = nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv18 = nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.conv19 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv20 = nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv21 = nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv22 = nn.Conv2d(1024, 1024, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv23 = nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv24 = nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(200704, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 7 * 7 * (1 + 2 * 5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.maxPool1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = self.maxPool2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.conv3(x))           \n",
    "        x = F.leaky_relu(self.conv4(x))           \n",
    "        x = F.leaky_relu(self.conv5(x))           \n",
    "        x = F.leaky_relu(self.conv6(x))           \n",
    "        x = self.maxPool3(x)                      \n",
    "\n",
    "        x = F.leaky_relu(self.conv7(x))           \n",
    "        x = F.leaky_relu(self.conv8(x))           \n",
    "        x = F.leaky_relu(self.conv9(x))           \n",
    "        x = F.leaky_relu(self.conv10(x))          \n",
    "        x = F.leaky_relu(self.conv11(x))          \n",
    "        x = F.leaky_relu(self.conv12(x))         \n",
    "        x = F.leaky_relu(self.conv13(x))          \n",
    "        x = F.leaky_relu(self.conv14(x))          \n",
    "\n",
    "        x = F.leaky_relu(self.conv15(x))          \n",
    "        x = F.leaky_relu(self.conv16(x))          \n",
    "        x = self.maxPool4(x)                      \n",
    "\n",
    "        x = F.leaky_relu(self.conv17(x))         \n",
    "        x = F.leaky_relu(self.conv18(x))         \n",
    "        x = F.leaky_relu(self.conv19(x))          \n",
    "        x = F.leaky_relu(self.conv20(x))          \n",
    "        x = F.leaky_relu(self.conv21(x))          \n",
    "        x = F.leaky_relu(self.conv22(x))\n",
    "        x = F.leaky_relu(self.conv23(x))\n",
    "        x = F.leaky_relu(self.conv24(x))                  \n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(x.size(0), -1)                 \n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.leaky_relu(self.fc1(x))            \n",
    "        x = F.leaky_relu(self.fc2(x))            \n",
    "        x = self.fc3(x)                           \n",
    "        \n",
    "        # Reshape the final output for YOLO\n",
    "        x = x.view(-1, 7, 7, (1 + 2 * 5))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "    Calculates Intersection over Union (IoU) between two sets of bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        boxes_preds (tensor): Predicted bounding boxes of shape (N, 4).\n",
    "                              Format depends on `box_format`.\n",
    "        boxes_labels (tensor): Ground truth bounding boxes of shape (N, 4).\n",
    "                               Format depends on `box_format`.\n",
    "        box_format (str): \"midpoint\" or \"corners\".\n",
    "                          - \"midpoint\": (x_center, y_center, width, height)\n",
    "                          - \"corners\": (x_min, y_min, x_max, y_max)\n",
    "\n",
    "    Returns:\n",
    "        tensor: IoU for each bounding box, shape (N).\n",
    "    \"\"\"\n",
    "    if box_format == \"midpoint\":\n",
    "        # Convert from midpoint to corners\n",
    "        box1_x1 = boxes_preds[..., 0] - boxes_preds[..., 2] / 2\n",
    "        box1_y1 = boxes_preds[..., 1] - boxes_preds[..., 3] / 2\n",
    "        box1_x2 = boxes_preds[..., 0] + boxes_preds[..., 2] / 2\n",
    "        box1_y2 = boxes_preds[..., 1] + boxes_preds[..., 3] / 2\n",
    "        box2_x1 = boxes_labels[..., 0] - boxes_labels[..., 2] / 2\n",
    "        box2_y1 = boxes_labels[..., 1] - boxes_labels[..., 3] / 2\n",
    "        box2_x2 = boxes_labels[..., 0] + boxes_labels[..., 2] / 2\n",
    "        box2_y2 = boxes_labels[..., 1] + boxes_labels[..., 3] / 2\n",
    "    elif box_format == \"corners\":\n",
    "        # If already in corner format\n",
    "        box1_x1, box1_y1, box1_x2, box1_y2 = boxes_preds[..., 0], boxes_preds[..., 1], boxes_preds[..., 2], boxes_preds[..., 3]\n",
    "        box2_x1, box2_y1, box2_x2, box2_y2 = boxes_labels[..., 0], boxes_labels[..., 1], boxes_labels[..., 2], boxes_labels[..., 3]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid box_format. Choose 'midpoint' or 'corners'.\")\n",
    "\n",
    "    # Intersection coordinates\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)\n",
    "\n",
    "    # Calculate areas of both boxes\n",
    "    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)\n",
    "    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)\n",
    "\n",
    "    # Calculate union area\n",
    "    union = box1_area + box2_area - intersection + 1e-6  # Add epsilon to avoid division by zero\n",
    "\n",
    "    # IoU\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from utils import intersection_over_union\n",
    "\n",
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=1, lambda_coord=5, lambda_noobj=0.5):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.S = S  # Grid size (SxS)\n",
    "        self.B = B  # Number of bounding boxes per grid cell\n",
    "        self.C = C  # Number of classes\n",
    "        self.lambda_coord = lambda_coord  # Weight for localization loss\n",
    "        self.lambda_noobj = lambda_noobj  # Weight for no-object confidence loss\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
    "\n",
    "        # Compute IoU for bounding boxes\n",
    "        iou_b1 = self.compute_iou(predictions[..., 1:5], target[..., 1:5])\n",
    "        iou_b2 = self.compute_iou(predictions[..., 6:10], target[..., 6:10])\n",
    "        ious = torch.stack((iou_b1, iou_b2), dim=0)\n",
    "\n",
    "        # Select the best bounding box\n",
    "        iou_maxes, bestbox = torch.max(ious, dim=0)\n",
    "        exists_box = target[..., 0].unsqueeze(3)\n",
    "        bestbox = bestbox.unsqueeze(-1)\n",
    "\n",
    "        # Box Predictions\n",
    "        box_predictions = exists_box * (\n",
    "            bestbox * predictions[..., 6:10]\n",
    "            + (1 - bestbox) * predictions[..., 1:5]\n",
    "        )\n",
    "        box_predictions_sqrt = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(\n",
    "            torch.abs(box_predictions[..., 2:4]) + 1e-6\n",
    "        )\n",
    "\n",
    "        # Box Targets\n",
    "        box_targets = exists_box * target[..., 1:5]\n",
    "\n",
    "        box_predictions_sqrt = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(\n",
    "            torch.abs(box_predictions[..., 2:4]) + 1e-6\n",
    "        )\n",
    "        box_targets_sqrt = torch.sqrt(torch.abs(box_targets[..., 2:4]) + 1e-6)\n",
    "\n",
    "        box_targets = box_targets.unsqueeze(-2).expand_as(box_predictions)\n",
    "        \n",
    "        # Compute box loss\n",
    "        box_loss = self.mse(\n",
    "            torch.flatten(box_predictions[..., :2], start_dim=1),\n",
    "            torch.flatten(box_targets[..., :2], start_dim=1),\n",
    "        ) + self.mse(\n",
    "            torch.flatten(box_predictions_sqrt, start_dim=1),\n",
    "            torch.flatten(box_targets_sqrt, start_dim=1),\n",
    "        )\n",
    "\n",
    "        # Confidence Loss\n",
    "        pred_conf = bestbox * predictions[..., 5] + (1 - bestbox) * predictions[..., 0]\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_box * pred_conf),\n",
    "            torch.flatten(exists_box * target[..., 0]),\n",
    "        )\n",
    "\n",
    "        # No-Object Loss\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., 0]),\n",
    "            torch.flatten((1 - exists_box) * target[..., 0]),\n",
    "        ) + self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., 5]),\n",
    "            torch.flatten((1 - exists_box) * target[..., 0]),\n",
    "        )\n",
    "\n",
    "        # Class Loss\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_box * predictions[..., :self.C], end_dim=-2),\n",
    "            torch.flatten(exists_box * target[..., :self.C], end_dim=-2),\n",
    "        )\n",
    "\n",
    "        # Total Loss\n",
    "        total_loss = (\n",
    "            self.lambda_coord * box_loss\n",
    "            + object_loss\n",
    "            + self.lambda_noobj * no_object_loss\n",
    "            + class_loss\n",
    "        )\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_iou(boxes1, boxes2):\n",
    "        \"\"\"\n",
    "        Compute the Intersection over Union (IoU) for predicted and target boxes.\n",
    "        \n",
    "        Args:\n",
    "        boxes1 (torch.Tensor): Predicted boxes, shape (N, S, S, B, 4)\n",
    "        boxes2 (torch.Tensor): Target boxes, shape (N, S, S, B, 4)\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: IoU scores, shape (N, S, S, B)\n",
    "        \"\"\"\n",
    "        # Unpack coordinates\n",
    "        b1_x1 = boxes1[..., 0:1] - boxes1[..., 2:3] / 2\n",
    "        b1_y1 = boxes1[..., 1:2] - boxes1[..., 3:4] / 2\n",
    "        b1_x2 = boxes1[..., 0:1] + boxes1[..., 2:3] / 2\n",
    "        b1_y2 = boxes1[..., 1:2] + boxes1[..., 3:4] / 2\n",
    "        \n",
    "        b2_x1 = boxes2[..., 0:1] - boxes2[..., 2:3] / 2\n",
    "        b2_y1 = boxes2[..., 1:2] - boxes2[..., 3:4] / 2\n",
    "        b2_x2 = boxes2[..., 0:1] + boxes2[..., 2:3] / 2\n",
    "        b2_y2 = boxes2[..., 1:2] + boxes2[..., 3:4] / 2\n",
    "        \n",
    "        # Intersection coordinates\n",
    "        inter_x1 = torch.max(b1_x1, b2_x1)\n",
    "        inter_y1 = torch.max(b1_y1, b2_y1)\n",
    "        inter_x2 = torch.min(b1_x2, b2_x2)\n",
    "        inter_y2 = torch.min(b1_y2, b2_y2)\n",
    "        \n",
    "        # Intersection area\n",
    "        inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)\n",
    "        \n",
    "        # Union area\n",
    "        b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "        b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "        union_area = b1_area + b2_area - inter_area\n",
    "        \n",
    "        return inter_area / torch.clamp(union_area, min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 45.83 GB, other allocations: 38.80 MB, max allowed: 45.90 GB). Tried to allocate 49.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 71\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m train_model(model, train_loader, criterion, optimizer)\n",
      "Cell \u001b[0;32mIn[56], line 39\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         targets[idx, grid_x, grid_y, \u001b[38;5;241m6\u001b[39m:] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m*\u001b[39mbox[\u001b[38;5;241m1\u001b[39m:]])  \u001b[38;5;66;03m# 두 번째 박스        \u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Debugging assertion\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m targets\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match target shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtargets\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 56\u001b[0m, in \u001b[0;36myoloV1.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 56\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[1;32m     57\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxPool1(x)\n\u001b[1;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:1677\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1675\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mleaky_relu_(\u001b[38;5;28minput\u001b[39m, negative_slope)\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1677\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28minput\u001b[39m, negative_slope)\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 45.83 GB, other allocations: 38.80 MB, max allowed: 45.90 GB). Tried to allocate 49.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = yoloV1().to(device)\n",
    "\n",
    "\n",
    "batch_size =1\n",
    "\n",
    "drive_train_dir = './drive_image_data/train'\n",
    "train_dataset = DriveYoloDataset(root_dir=drive_train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "criterion = YoloLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    S, B, C = 7, 2, 1  # Grid size, bounding boxes, and classes\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for images, boxes, labels in loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Initialize targets\n",
    "            targets = torch.zeros((batch_size, 7, 7, 1 + 2 * 5)).to(device)  # 1 for class, 2 boxes, 5 values each\n",
    "            for idx in range(len(boxes)):  # boxes: 각 이미지의 바운딩 박스 리스트\n",
    "                for box in boxes[idx]:    # box: 각 박스의 (class, x, y, w, h)\n",
    "                    grid_x, grid_y = int(box[1] * 7), int(box[2] * 7)  # 그리드 위치\n",
    "                    targets[idx, grid_x, grid_y, 0] = labels[idx]  # 클래스 (binary)\n",
    "                    targets[idx, grid_x, grid_y, 1:6] = torch.tensor([1.0, *box[1:]])  # 첫 번째 박스\n",
    "                    targets[idx, grid_x, grid_y, 6:] = torch.tensor([1.0, *box[1:]])  # 두 번째 박스        \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Debugging assertion\n",
    "            assert outputs.shape == targets.shape, f\"Output shape {outputs.shape} does not match target shape {targets.shape}\"\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute IoU-based accuracy\n",
    "            for i in range(len(images)):\n",
    "                pred_boxes = outputs[i, ..., C + 1:C + 5].detach()\n",
    "                true_boxes = targets[i, ..., C + 1:C + 5].detach()\n",
    "                pred_classes = torch.argmax(outputs[i, ..., :C], dim=-1)\n",
    "                true_classes = torch.argmax(targets[i, ..., :C], dim=-1)\n",
    "\n",
    "                ious = intersection_over_union(pred_boxes, true_boxes)\n",
    "                correct_iou = (ious > 0.5).sum().item()\n",
    "                correct_predictions += correct_iou\n",
    "\n",
    "                total_predictions += (true_classes > 0).sum().item()  # Count valid true boxes\n",
    "\n",
    "        # Compute accuracy percentage\n",
    "        accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
